
# Pipeline ETL â€“ Dados PÃºblicos do Portal da TransparÃªncia

Este projeto implementa um **pipeline ETL completo** utilizando **dados pÃºblicos do Portal da TransparÃªncia**, com o objetivo de consolidar conhecimentos em **Python, Pandas, SQL e Engenharia de Dados**.

O pipeline segue uma **arquitetura em camadas (Bronze, Silver e Gold)**, garantindo organizaÃ§Ã£o, rastreabilidade e possibilidade de evoluÃ§Ã£o para cenÃ¡rios de produÃ§Ã£o.

---

## Arquitetura do Projeto

```
etl_dados_publicos/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ a_extract.py        # ExtraÃ§Ã£o de dados (Bronze)
â”‚   â”œâ”€â”€ b_transform.py     # TransformaÃ§Ã£o e normalizaÃ§Ã£o (Silver)
â”‚   â”œâ”€â”€ c_load.py          # Carga no MySQL
â”‚   â”œâ”€â”€ main.py            # OrquestraÃ§Ã£o do pipeline
â”‚   â””â”€â”€ logger_config.py   # ConfiguraÃ§Ã£o de logs
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/            # Dados brutos (JSON)
â”‚   â””â”€â”€ silver/            # Dados tratados (Parquet)
â”‚
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ ddl.sql            # Estrutura das tabelas (DDL)
â”‚   â””â”€â”€ gold_views.sql     # Views analÃ­ticas (Gold)
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ .env.example           # Exemplo de variÃ¡veis de ambiente
â”œâ”€â”€ requirements.txt       # DependÃªncias do projeto
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## Camada Bronze â€“ ExtraÃ§Ã£o

A camada **Bronze** armazena os dados **exatamente como vÃªm da fonte**, sem transformaÃ§Ãµes.

### Fontes utilizadas

* **Portal da TransparÃªncia â€“ API oficial**

  * Tipos de transferÃªncia de despesas
  * Documentos de despesas pÃºblicas

### CaracterÃ­sticas

* AutenticaÃ§Ã£o via **API Key**
* PaginaÃ§Ã£o controlada
* PersistÃªncia em **JSON**
* Rastreabilidade garantida

Arquivos gerados:

* `despesas_tipos_transferencia_YYYY_MM_DD.json`
* `despesas_documentos_YYYY_MM_DD.json`

---

## Camada Silver â€“ TransformaÃ§Ã£o

A camada **Silver** Ã© responsÃ¡vel por:

* Limpeza
* PadronizaÃ§Ã£o
* NormalizaÃ§Ã£o
* ConversÃ£o para formato analÃ­tico

### TransformaÃ§Ãµes realizadas

* NormalizaÃ§Ã£o de JSON aninhado (`pd.json_normalize`)
* PadronizaÃ§Ã£o de nomes de colunas
* Tratamento de valores invÃ¡lidos (`"-"`, `null`)
* CriaÃ§Ã£o de chave de documento (`doc_key`)
* ConversÃ£o para **Parquet (formato colunar)**

Arquivos gerados:

* `dim_tipo_transferencia_YYYY_MM_DD.parquet`
* `fato_documentos_despesa_YYYY_MM_DD.parquet`

---

## Camada Gold â€“ Camada AnalÃ­tica

A camada **Gold** Ã© composta por **views SQL**, prontas para consumo por ferramentas de BI ou anÃ¡lises exploratÃ³rias.

### Views disponÃ­veis

#### ğŸ”¹ Valor total por tipo de transferÃªncia

```sql
vw_total_valor_por_tipo_transferencia
```

#### ğŸ”¹ Quantidade de documentos por mÃªs

```sql
vw_documentos_por_mes
```

#### ğŸ”¹ Auditoria e rastreabilidade

```sql
vw_auditoria_documentos
```

Essas views permitem responder perguntas de negÃ³cio sem impactar as tabelas base.

---

## Banco de Dados

* **MySQL**
* Modelagem em estrela:

  * DimensÃ£o: `dim_tipo_transferencia`
  * Fato: `fato_documento_despesa`
* Uso de **ON DUPLICATE KEY UPDATE** para garantir **idempotÃªncia**

---

## OrquestraÃ§Ã£o

O pipeline Ã© orquestrado pelo arquivo:

```bash
src/main.py
```

Ele executa, em ordem:

1. Extract (Bronze)
2. Transform (Silver)
3. Load (MySQL)

O pipeline pode ser executado mÃºltiplas vezes sem duplicar dados.

---

## Logs

O projeto utiliza o mÃ³dulo `logging` com:

* Logs no console
* Logs persistidos em `logs/etl.log`
* Registro de erros com stacktrace
* RotaÃ§Ã£o automÃ¡tica de arquivos

Exemplo de log:

```
2026-02-08 09:55:08 | INFO | etl | Pipeline concluÃ­do em 1.7s
```

---

## VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto com base em `.env.example`.

Principais variÃ¡veis:

```env
PT_API_KEY=xxxxxxxxxxxxxxxx
DB_HOST=localhost
DB_PORT=3306
DB_USER=root
DB_PASSWORD=senha
DB_NAME=etl_dados_publicos

DOCS_UNIDADE_GESTORA=175004
DOCS_GESTAO=00001
DOCS_DATA_EMISSAO=13/01/2023
DOCS_FASE=2
DOCS_MAX_PAGINAS=1
DOCS_PAGE_SIZE=50
```

---

## â–¶ Como Executar o Projeto

### 1ï¸âƒ£ Criar ambiente virtual

```bash
python -m venv .venv
```

### 2ï¸âƒ£ Ativar ambiente

```bash
# Windows
.\.venv\Scripts\Activate.ps1
```

### 3ï¸âƒ£ Instalar dependÃªncias

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Executar pipeline

```bash
python src/main.py
```

---

## Conceitos Aplicados

* ETL (Extract, Transform, Load)
* Arquitetura MedalhÃ£o (Bronze / Silver / Gold)
* Engenharia de Dados com Python, Pandas e Banco de Dados


---

## Autor

Projeto desenvolvido por **Geraldo Mendes de Pontes Neto**,
Estudando de Sistemas de InformaÃ§Ãµes pela UFPB.



